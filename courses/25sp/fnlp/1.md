# Lecture 1 - Introduction
Fundamentals of Natural Language Processing, 2025 Spring

?> 本课程笔记整理自草鱼，部分补充内容由 deepseek 或 gpt 生成。如有错误，欢迎指正！

!> **Scores** Assignments + Labs : Midterm Exam : In-class Participation ≈ 60 : 30 : 10

## Why do we care about languages?

语言可以分成**形式语言**和**自然语言**。**自然语言**（Natural Language）就是人类讲的语言，比如汉语、英语和法语。这类语言不是人为设计（虽然有人试图强加一些规则）而是自然进化的。**形式语言**（Formal Language）是为了特定应用而人为设计的语言。例如数学家用的数字和运算符号、化学家用的分子式等。编程语言也是一种形式语言，是专门设计用来表达计算过程的形式语言。

![alt text](1742031746086.png ':size=60%')

### The computational modeling of Human Language
* **Morphology 词法学** — the structure of words
* **Syntax 句法，句子结构** — the way words are used to form sentences
* **Semantics 语义学**
  + Lexical semantics 词汇语义学 — the meaning of individual words
  + Compositional semantics 组合语义学 — the construction of meaning based on syntax
* **Pragmatics 语用学** — meaning in context
* **Language generation 文章的生成** — meaning in context

### Computation & Production
我们将会学习从自然语言表达到多种语言结构的转换过程，以及从意义表示到具体语言形式的生成过程。

具体来说，从自然语言表达 natural language expressions 出发，我们可以分析其**形态结构** morphological structure （即词汇的构成和形态变化），**句法结构** syntactic structure （句子的语法组织和成分关系），**语义结构** semantic structure （词汇和句子的意义及其关系），**篇章结构** discourse structure （段落和文章的组织方式），以及**应用相关结构** application-related structure （特定任务或领域中的语言特征）。

另一方面，从意义表示出发，我们可以生成具体的语言形式，包括**词和短语** words and phrases （将意义映射到词汇层面），**句子** sentences （将意义组织成符合语法的句子），**段落** paragraphs （将多个句子组织成连贯的段落），以及**文章** articles （将多个段落整合成完整的文章）。这些过程涵盖了自然语言处理中的理解和生成任务，是语言分析和生成的核心内容。

## What is Natural Language Processing?

**自然语言处理（Natural Language Processing, NLP）** 是一门研究如何让计算机理解、生成和处理人类语言的学科。其核心任务是帮助计算机以人类语言作为输入和/或输出（如 M. Collins 所述, Help computers use human language as input and/or output）。具体来说，NLP 可以分为两个主要方向：  
1. **作为输入的自然语言理解（Natural Language Understanding, NLU）**：即让计算机理解人类语言，包括语音识别（speech recognition）、词性标注（tagging）、句法分析（parsing）、信息抽取（information extraction）等任务。  
2. **作为输出的自然语言生成（Natural Language Generation, NLG）**：即让计算机生成人类可理解的语言，包括内容规划（content planning）、表层实现（surface realization）、文本摘要（summarization）、语音合成（speech synthesis）等任务。  

此外，NLP 还涉及更复杂的任务，例如问答系统（question answering）、对话系统（dialogue）、机器翻译（machine translation）等。这些任务通常需要结合语言理解和生成的能力。  

在计算方法上，NLP 的发展经历了多个阶段：  
- **符号模型（Symbolic Models）**：基于规则和逻辑的方法，早期 NLP 主要依赖此类模型。  
- **统计模型（Statistical Models）**：利用概率和统计方法从数据中学习语言规律，如隐马尔可夫模型（HMM）和条件随机场（CRF）。  
- **神经模型（Neural Models）**：基于深度学习的方法，如循环神经网络（RNN）和 Transformer 架构。  
- **预训练语言模型（Pre-trained Language Models）**：如 BERT、GPT 等，通过大规模数据预训练获得通用语言表示能力。  
- **大语言模型或基础模型（Large Language Models or Foundation Models）**：如 GPT-3、ChatGPT 等，具有极强的语言生成和理解能力，能够适应多种下游任务。  

NLP 的目标是通过计算模型实现人机之间的自然语言交互，其应用广泛，涵盖了从语音助手到机器翻译、从文本分析到智能对话系统等多个领域。

?> NLP的应用很广泛。课程中列举了信息提取、情感分析、问题回复、机器理解等多个实例，在此不一一列举。

## Challenges in NLP
### Ambiguity
同样的句子可能有不同的结构，进而有不同的解释。

![alt text](1742037782308.png ':size=60%')

### 更多挑战

1. **语言多样性（Variation）**：仅中国就有数百种语言和方言，全球语言更是超过 7,000 种，这增加了语言处理的复杂性。  
2. **数据稀疏性（Sparsity）**：无论语言或数据规模如何，低频词总是远多于高频词（如齐夫定律 Zipf’s Law 所述），这导致模型难以学习到足够的低频词信息。  

此外，还有一些未被充分解决的问题：  
- 如何比较“老虎”和“猫”的大小？  
- 如何准确描述人类动作，例如“深蹲（Squat）”？  

这些挑战表明，NLP 需要在语言多样性、数据稀疏性以及复杂语义理解方面进一步突破。

![alt text](1742038098620.png ':size=60%')

