# Lecture 7 - Syntactic Analysis I
Fundamentals of Natural Language Processing, 2025 Spring

?> 本课程笔记整理自Freefizing & 草鱼。

!> **重点内容：** 上下文无关文法、语义分析、CFG 算法


从这节课开始，我们学习**句法分析**。我们已经学过词义和短语层面的了，现在我们上升到句法层面。

先来明确几个概念吧。

1. Consituent “短语” *（其实貌似没有一个很好的中文翻译）* 指代构成句法结构的独立单位。
2. Phrase Structure：短语结构。基本的 idea 是把 Consituent 建成一个树结构。

![alt text](image-43.png 'size=80%')


## 上下文无关文法 (Context-Free Grammars, CFGs)

先来看最简单的一种文法：**上下文无关文法 (CFG)**。由以下部分组成：

- **有限集合** \(\Sigma\)：终结符（Terminal symbols），例如单词、字符等。
- **有限集合** \(N\)：非终结符（Nonterminal symbols），且与 \(\Sigma\) 互不相交。
  - 其中，**START** 符号 \( S \in N \) 代表文法的起始符号。
- **有限集合** \(R\)：产生式规则（Production rules），每条规则的形式如下：
  
  $$
  A \to (\Sigma \cup N)^*, A \in N
  $$

  其中：
  - 左侧 **\( A \)** 必须是**非终结符**。
  - 右侧是**由零个或多个终结符和/或非终结符组成的序列**。
    - 我们可以对右侧的形式施加约束，例如：长度、类型等。

?> 为什么称为“上下文无关”呢？上下文无关强调**无论非终结符出现在什么位置，它都可以按照相同的规则被替换**，而不会受到周围符号的影响。这使得解析和推导更加简单，并且能够使用递归下降或自顶向下/自底向上的解析算法来处理。

> 例：一个简单的上下文无关文法分析

**文法定义**
- **非终结符集合** \(N\)：
  $$
  N = \{ S, NP, VP, AdjP, AdvP \} \cup \{ N, Adj, Adv \}
  $$
- **终结符集合** \(\Sigma\)：
  $$
  \Sigma = \{ \text{colorless, green, ideas, sleep, furiously} \}
  $$
- **产生式规则** \(R\)：
  $$
  R = 
  \begin{cases}
  S \to NP\ VP \\
  VP \to VP\ AdvP \\
  VP \to V \\
  AdvP \to Adv \\
  NP \to AdjP\ NP \\
  NP \to N \\
  AdjP \to Adj \\
  \textbf{Adj} \to \text{colorless},\ \textbf{N} \to \text{ideas},\ \textbf{Adv} \to \text{furiously}, \\
  \textbf{Adj} \to \text{green},\ \textbf{V} \to \text{sleep}
  \end{cases}
  $$
- 起始符号：
  $$
  S = S
  $$

**句子结构推导 (Derivation Process)**

我们可以使用上述文法推导出句子的结构：
1. \( S \Rightarrow NP\ VP \)
2. \( \Rightarrow N\ VP \)
3. \( \Rightarrow \text{ideas}\ VP \)
4. \( \Rightarrow \text{ideas}\ VP\ AdvP \)
5. \( \Rightarrow \text{ideas}\ V\ AdvP \)
6. \( \Rightarrow \text{ideas}\ \text{sleep}\ AdvP \)
7. \( \Rightarrow \text{ideas}\ \text{sleep}\ Adv \)
8. \( \Rightarrow \text{ideas}\ \text{sleep}\ \text{furiously} \)


### Grammar Equivalence 语法等价

如果两个文法 \( G_1 \) 和 \( G_2 \) **生成相同的字符串集合**，即：
$$
L(G_1) = L(G_2)
$$
那么我们称它们是**等价的**。

但是，等价性可以进一步细分为**强等价**和**弱等价**。

| **等价类型** | **定义** |
|-------------|---------|
| **强等价 (Strong Equivalence)** | 生成相同的字符串集合，并且赋予相同的短语结构。 |
| **弱等价 (Weak Equivalence)** | 生成相同的字符串集合，但短语结构可能不同。 |

### 乔姆斯基范式 (Chomsky Normal Form, CNF)

在乔姆斯基范式中，一个上下文无关文法 (CFG)  \( G = (N, \Sigma, R, S) \) 需要满足以下条件：

- **\(N\)** 是非终结符（Non-terminal）符号的集合。
- **\(\Sigma\)** 是终结符（Terminal）符号的集合。
- **\(S \in N\)** 是唯一的开始符号（Start Symbol）。
- **\(R\)** 是一组产生规则（Production Rules），每条规则必须符合以下两种形式之一：
  - **\( X \to YZ \)** ，其中 **\( X \in N, Y \in N, Z \in N \)** （两个非终结符）。
  - **\( X \to x \)** ，其中 **\( X \in N, x \in \Sigma \)** （一个非终结符推导一个终结符）。

**每个上下文无关文法 (CFG) 都可以转换为等价的乔姆斯基范式 (CNF)。**

---

## 概率型上下文无关文法 (PCFG)

### 句法树 (Syntax Tree) 的概率计算

给定一个句法树 \( t \) ，它的规则序列为：
\[
A_1 \to \beta_1, A_2 \to \beta_2, \dots
\]
那么这棵树的概率计算公式为：
\[
p(t) = \prod_{i=1}^{n} q(A_i \to \beta_i)
\]
其中：
- \( q(A_i \to \beta_i) \) 表示 **规则** \( A_i \to \beta_i \) **的概率**。
- \( p(t) \) 表示整个句法树的概率。

---

**规则的选择概率**

对于每个**非终结符** \( A_i \)，它的所有可能的规则满足：
$$
\sum_{\beta} q(A_i \to \beta \mid A_i) = 1
$$
即：
- 在扩展 \( A_i \) 时，每种规则的概率之和必须等于 1。

---

### PCFG 的特点

- **解析树概率分配**: PCFG 为每棵符合 CFG 的解析树 (parse-tree) 赋予概率。
- **句子派生集**:
  - 对于一个句子 \( s \)，所有符合 CFG 的派生构成集合 \( T(s) \)。
  - PCFG 为集合中的每棵树 \( t \) 分配概率 \( p(t) \)。
- **评分函数**:
  - PCFG 可以用概率作为评分函数，对解析树进行排名。
  - 最可能的解析树：
    $$
    \arg \max_{t \in T(s)} p(t)
    $$
- **术语**:
  - *Correct*：概率最高的解析树。
  - *Language*：符合语法的句子集合。

---

### 通过树库 (Treebank) 训练 PCFG
- **从语料库推导 PCFG**:
  - 通过一个示例解析树集合 (Treebank)，可以直接提取 CFG 规则。
  - 通过 **最大似然估计 (Maximum Likelihood Estimation, MLE)** 计算规则概率：
    $$
    q_{ML} (\alpha \rightarrow \beta) = \frac{\text{count}(\alpha \rightarrow \beta)}{\text{count}(\alpha)}
    $$
  - 其中 `count(α → β)` 表示在训练集中规则 `α → β` 的出现次数，`count(α)` 是 `α` 作为左侧符号的总次数。

- **收敛性**:
  - 若训练数据由某个 PCFG 生成，则随着数据集无限增大，最大似然估计得到的 PCFG 会收敛到真正的 PCFG 分布。

## CFG 算法
TODO
