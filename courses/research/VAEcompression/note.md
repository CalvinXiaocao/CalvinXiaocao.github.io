# Paper Reading: Variational Image Compression With A Scale Hyperscale

*图像压缩系列笔记 02*

?> 这是发表在 ICLR 2018 上的一篇论文，给出了端到端图像压缩的基本框架。作者基于 VAE 设计了一个端到端的可训练的图像压缩模型。与现有的模型不同，该模型与底层自动编码器联合训练复杂的先验。最终取得了当时 state-of-the-art 的效果。

## Introduction
有损图像压缩的一个最简单的原则是：对图像 $x$ 进行**量化** (quantize) 。量化减少了存储或传输它所需的信息量，但同时引入了 error。通常，直接量化的不是像素强度，而是先转到 **latent space** 变成 $y$ 再做量化得到 $\hat{y}$。因为 $\hat{y}$ 是离散的，所以可以使用熵编码方法（例如算术编码 Arithmetic Encoding）对其进行无损压缩。

有一点我们需要注意：我们需要区分潜在表示的实际边际分布 $m(\hat{y})$ 和熵模型对于潜在表示的熵模型分布 $p_{\hat{y}}(\hat{y})$。虽然通常假设熵模型具有参数化形式，并且参数适合数据，但是边缘 $m(\hat{y})$ 是未知的分布，当熵模型估计潜在表示出现值越精准，则其越接近理论熵值。编码器-解码器对可以实现的最小平均代码长度，使用 $p_{\hat{y}}$ 作为它们的共享熵模型，由两个分布之间的香农交叉熵给出。

$$
R=\mathbb{E}_{\hat{y}\sim m}[-\log_2 p_{\hat{y}}(\hat{y})]
$$

如果这两个分布相同的时候，就意味着交叉熵最小。这也表明当潜在表示的实际分布中存在统计依赖性时，使用完全分解的熵模型会导致压缩性能的非最优。

传统方法中，一种提升性能的方式是从编码器传输**额外信息** (side information) 给到解码器。我们希望传输的信息平均上尽可能比上面的式子优化出的 codelength 要小。比方说，**JPEG** 统一切成了 8*8 的像素块。而更近期的一些方法，比如 **HEVC**，把图片切成了不同的大小，把切分的信息也传给解码器，这样解码器先收到 side information，然后再去用正确的熵模型去解码。

传统的 side information 的形式是 hand-designed 人为设计的。相反，本文中介绍的模型本质上是**学习熵模型的潜在表示**，就像基础压缩模型学习图像的表示一样。该模型是端到端的优化模型，通过学习**平衡信息量和预期的熵模型改进**，可以使总的预期代码长度最小。怎么实现呢？使用 VAE 来完成。

在 2017 年的时候，作者就指出，一些基于自动编码器的压缩方法形式上和 VAE 是等价的。其中熵模型对应于潜在表示中的先验模型。而在这里，辅助信息可以被视为模型参数的先验，使它们成为潜在表示的**超先验** （hyperprior）。

这篇工作则是对作者 2017 年提出的模型做了扩展，它具有先验网络，并具有一个超先验的功能，即表示潜在表示的空间相邻元素在其比例尺上倾向于一起变化，并且通过实验表明它具有很好的效果。

## Compression With Variational Models
